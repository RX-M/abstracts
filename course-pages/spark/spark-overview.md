<!-- Apache Spark Overview -->

This one-day Apache Spark training course is for data engineers, analysts, architects, software engineers, IT operations and technical managers interested in a brief hands-on overview of the Apache Spark platform. The course covers core APIs for using Spark, basic internals of the platform, SQL and other high-level data access tools, as well as Sparkâ€™s streaming capabilities and machine learning APIs.

Each topic includes lecture content along with hands-on use of a Spark cluster in lab exercises. After attending the training, students will be able to: communicate with team members using appropriate terminology; identify and experiment with use cases for Spark and Databricks appropriate to business needs; build data pipelines and query large data sets using Spark SQL and DataFrames; execute and modify ETL jobs using the Spark API, DataFrames and RDDs; and analyze Spark jobs using the UIs and logs.


### Delivery

Available for Instructor-Led (ILT) in-person/onsite training or Virtual Instructor-Led training (VILT) delivery; Open Enrollment options may be available.


### Who Should Attend?

Application Developers, Analysts and Data Scientists


### What Attendees will learn

This course is designed to provide attendees with a comprehensive introduction to Apache Spark and SparkSQL. Learning modules include:

- Internals of the Apache Spark Platform
- Working with key/value data and file based data
- Querying Hadoop and JDBC/ODBC sources with SparkSQL



### Prerequisites

Each attendee will require the ability to run a 64 bit virtual machine (provided with the course). Basic Linux command
line skills are helpful. The coding examples use Python and PySpark so some experience with Python is important.
